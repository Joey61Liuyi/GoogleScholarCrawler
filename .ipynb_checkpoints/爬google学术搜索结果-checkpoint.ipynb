{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/python\n",
    "#encoding=utf-8\n",
    "__author__ = 'Administrator'\n",
    "from selenium import selenium\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    import os\n",
    "    from selenium import webdriver\n",
    "    from selenium.webdriver.support.ui import WebDriverWait\n",
    "\n",
    "    chromedriver = \"C:\\Program Files\\Google\\Chrome\\Application\\chromedriver.exe\"\n",
    "    os.environ[\"webdriver.chrome.driver\"] = chromedriver\n",
    "    driver = webdriver.Chrome(chromedriver)\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    driver.get('http://www.gfsoso.com/scholar')\n",
    "    inputElement = driver.find_element_by_name(\"q\")\n",
    "    searchWord=\"sentiment lexicon\"\n",
    "    inputElement.send_keys(searchWord)\n",
    "    inputElement.submit()\n",
    "    currentURL=driver.current_url\n",
    "    urlList=[]\n",
    "    localDir = 'down_pdf\\\\'\n",
    "    fileOut = localDir + searchWord + \".txt\"\n",
    "    import urllib, re,codecs,sys\n",
    "    fileOp = codecs.open(fileOut, 'a', sys.getdefaultencoding())\n",
    "    for i in range(0,10):#需要抓取的页数\n",
    "        pdf_url = driver.find_elements_by_css_selector(\"a\")\n",
    "        for k in pdf_url:\n",
    "            try:\n",
    "                z= k.get_attribute(\"href\")\n",
    "                if '.pdf' in z and z not in urlList:\n",
    "                    urlList.append(z)\n",
    "                    print z\n",
    "            except:\n",
    "                import time\n",
    "                time.sleep(1)\n",
    "                continue\n",
    "        contents=driver.find_elements_by_css_selector('h3')\n",
    "        for ct in contents:\n",
    "            print ct.text\n",
    "            #fileOp.write('%s\\n' %(ct.text))#把页面上所有的文章名称存到txt，有时会报错\n",
    "        driver.get(currentURL+\"&start=\"+str(i*10)+\"&as_sdt=0,5&as_ylo=2008\")\n",
    "        import time\n",
    "        time.sleep(3)\n",
    "    print len(urlList)\n",
    "\n",
    "    for everyURL in urlList:                                  #遍历列表的每一项，即每一个PDF的url\n",
    "            wordItems = everyURL.split('/')                   #将url以/为界进行划分，为了提取该PDF文件名\n",
    "            for item in wordItems:                            #遍历每个字符串\n",
    "                    if re.match('.*\\.pdf$', item):            #查找PDF的文件名\n",
    "                            PDFName = item                    #查找到PDF文件名\n",
    "            localPDF = localDir +searchWord+\"_\"+ PDFName                   \n",
    "            try:\n",
    "                    urllib.urlretrieve(everyURL, localPDF)    #按照url进行下载，并以其文件名存储到本地目录\n",
    "            except Exception,e:\n",
    "                    continue"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
